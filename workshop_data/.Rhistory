load_or_install = function(package_name){
if (!require(package_name)){
install.packages(package_name)
}
library(package_name)
}
load_or_install('lexicon')
if (!require(stringr)){
install.packages('stringr')
}
library(package)
if (!require(stringr)){
install.packages('stringr')
}
library(stringr)
setwd('/Users/bennettkleinberg/GitHub/ltta_workshop_data/data_for_workshop')
load('./main_data/eurocss_ltta_workshop_data_sampled.RData')
setwd('/Users/bennettkleinberg/GitHub/ltta_workshop/workshop_data')
load('./youtube_vloggers_emnlp_data/youtube_vlogs_sentiments_05052018.RData')
View(head(df.sentiments))
dt.sentiments = setDT(df.sentments)
# PREPARATION
## clear ws
rm(list = ls())
setwd('/Users/bennettkleinberg/GitHub/ltta_workshop/workshop_data')
load('./youtube_vloggers_emnlp_data/youtube_vlogs_sentiments_05052018.RData')
require(data.table)
dt.sentiments = setDT(df.sentments)
dt.sentiments = setDT(df.sentiments)
dt.sentiments
dt.sentiments = setDT(t(df.sentiments))
load('./youtube_vloggers_emnlp_data/youtube_vlogs_sentiments_05052018.RData')
dt.sentiments = setDT(t(df.sentiments))
df.sentiments
t(df.sentiments)
rm(list = ls())
setwd('/Users/bennettkleinberg/GitHub/ltta_workshop/workshop_data')
load('./youtube_vloggers_emnlp_data/youtube_vlogs_sentiments_05052018.RData')
setwd('/Users/bennettkleinberg/GitHub/ltta_workshop/workshop_data/sample_data/caseyneistat')
source('/Users/bennettkleinberg/GitHub/r_helper_functions/txt_df_from_dir.R')
setwd('/Users/bennettkleinberg/GitHub/ltta_workshop/workshop_data')
vlogs_casey_neistat = txt_df_from_dir(dirpath = './sample_data/caseyneistat'
, recursive = F
, include_processed = F
, to_lower = F)
View(head(vlogs_casey_neistat))
View(head(vlogs_casey_neistat))
sentiment_shapes = ncs_full(txt_input_col = vlogs_casey_neistat$text
, txt_id_col = vlogs_casey_neistat$id
, low_pass_filter_size = 5
, transform_values = T
, normalize_values = F
, min_tokens = 10 #minimum length required to process a vlog
, cluster_lower = 3 #window size before sentiment
, cluster_upper = 3 #window size after sentiment
)
source('./r_deps/naive_context_sentiment/ncs.R')
sentiment_shapes = ncs_full(txt_input_col = vlogs_casey_neistat$text
, txt_id_col = vlogs_casey_neistat$id
, low_pass_filter_size = 5
, transform_values = T
, normalize_values = F
, min_tokens = 10 #minimum length required to process a vlog
, cluster_lower = 3 #window size before sentiment
, cluster_upper = 3 #window size after sentiment
)
View(sentiment_shapes)
View(sentiment_shapes[, 1:10])
nrow(sentiment_shapes)
names(sentiment_shapes)
vlogs_casey_neistat$id
vlogs_casey_neistat$Filename
names(sentiment_shapes) = vlogs_casey_neistat$Filename
names(sentiment_shapes)
plot(sentiment_shapes$`779.txt`)
plot(sentiment_shapes$`779.txt`
, type='h'
, ylim = c(-1.25, 1.25)
, main = 'Shape of file 770.txt'
, ylab = 'Sentiment'
, xlab = 'Standardized narrative time')
prop.table(sentiment_shapes$`779.txt` > 0)
prop.table(table(sentiment_shapes$`779.txt` > 0))
diff(sentiment_shapes$`779.txt`)
diff(sentiment_shapes$`779.txt`, differences = 1)
plot(sentiment_shapes$`779.txt`
, type='h'
, ylim = c(-1.25, 1.25)
, main = 'Shape of file 770.txt'
, ylab = 'Sentiment'
, xlab = 'Standardized narrative time')
setwd('/Users/bennettkleinberg/GitHub/ltta_workshop/workshop_data')
rm(list = ls())
#stringr
if (!require(stringr)){
install.packages('stringr')
}
library(stringr)
#data.table
if (!require(data.table)){
install.packages('data.table')
}
library(data.table)
#lexicon
if (!require(lexicon)){
install.packages('lexicon')
}
library(lexicon)
source('./r_deps/naive_context_sentiment/ncs.R')
source('./r_deps/txt_df_from_dir.R')
setwd('/Users/bennettkleinberg/GitHub/ltta_workshop/workshop_data')
rm(list = ls())
#stringr
if (!require(stringr)){
install.packages('stringr')
}
library(stringr)
#data.table
if (!require(data.table)){
install.packages('data.table')
}
library(data.table)
#lexicon
if (!require(lexicon)){
install.packages('lexicon')
}
library(lexicon)
source('./r_deps/naive_context_sentiment/ncs.R')
source('./r_deps/txt_df_from_dir.R')
