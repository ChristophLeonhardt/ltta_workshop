recent elections most notably that of
Donald Trump as US president have
highlighted the dangers to democracy
posed by those using social media and
the Internet to spread malicious
propaganda and fake news so how and why
are platforms such as Facebook Google
and Twitter so wide open to abuse in a
two-part special report we sent Bob
Abe's house to investigate
San Francisco and Silicon Valley tech
companies driving the digital revolution
see themselves as positive agents of
political and social change
Facebook's mission is all about giving
people a voice and bring people closer
together those are democratic values and
we're proud of them
googles mission was to organize the
world's information and make it
universally accessible and useful the
more you learn about technology the more
you learn what's possible at Twitter our
canvas is communication if we want to
see democracy it's up to us to make sure
that we empower by giving people better
tools but Russia's manipulation of these
platforms during the 2016 US
presidential election has raised
fundamental questions about their
systemic vulnerabilities you solemnly
swear to tell the truth last November
the companies were summoned to appear
before the US Senate Intelligence
Committee the threat is not new Russians
have been conducting information warfare
for decades but what is new is the
advent of social media tools with the
power to magnify propaganda and fake
news on a scale that was unimaginable
back in the days of the Berlin Wall
you've created these platforms and now
they are being misused and you have to
be the ones to do something about it or
we will what you're doing by allowing
this fake stuff to come across this
misleading this damaging information is
threatening the security and really the
sovereignty of our nation I wishes your
CEOs would be here they need ask answer
for this
after repeated pressure from Congress
Facebook disclosed last September that
470 fake accounts linked to a shadowy
company with ties to the Kremlin the
internet research agency had spent some
hundred thousand dollars to purchase
more than three thousand ads most on
divisive hot-button issue
this account promoted to pro Texas
causes an included post many would
characterize as anti-immigration or
anti-muslim the Russian sponsored
Facebook page heart of Texas attracted
nearly two hundred and fifty four
thousand followers part of Texas group
created a public event on Facebook to
occur at the Islamic Center in Houston
Texas to stop the Islamization of Texas
Russian operatives also created a page
for United Muslims of America a real
group whose name they commandeered to
promote a counter protest at the Islamic
Center but neither side could have known
is that Russia trolls we're encouraging
both sides to battle in the streets and
create division between real Americans
and causing this disruptive event in
Houston cost Russia about two hundred
dollars
the Russians created more than a hundred
Facebook pages to exacerbate social
divisions in the u.s. there were pages
for African American groups and police
advocates southern nationalists and
liberal activists LGBT supporters and
Christian fundamentalists army of Jesus
and other Russian pages ran anti Hillary
Clinton ads during the election each of
these fake accounts spend literally
months developing networks of real
people to follow and like their content
these networks are later utilized to
push an array of disinformation the day
before the hearing Facebook revealed
that Russian content reached as many as
a hundred and twenty six million
Americans Twitter found more than 36,000
Russian accounts that generated 1.4
million election related tweets seen
almost three hundred million times and
Google disclosed that Russian trolls
likely posted eleven hundred videos on
18 YouTube channels
this is a yes or no question do you
believe that any of your companies have
identified the full scope of Russian
active measures under platform senator
our investigation continues so I would
have to say no certainly not with
certainty that's tragic no and we're
still working on it
mr. Walker well we have done a
comprehensive investigation but these
are ongoing issues and we continue to
investigate we are relying on Twitter
Facebook and Google to find and reveal
this information and it's been dripping
out so I think we have a long way to go
before we know the full story Siva
Vaidhyanathan is director of the center
for media and citizenship at the
University of Virginia the author of the
Google ization of everything his new
book anti social media will be released
this year Russia interference is
alarming but the biggest effect that
social media have on the prospect of
democracy has to do with undermining our
ability as citizens to think and act
effectively and collectively why do you
think the world is in the midst of an
Internet assault on democracy since 2011
what we have seen is the rise of
authoritarian leaders often elected in
places like Poland like Hungary like
India like the Philippines Google and
Facebook and Twitter have all been used
by these forces and then in my own
country Donald Trump laid almost all of
his hopes on a Facebook based campaign I
late 2017 Facebook reached almost 2.2
billion people that's stunning and if
you were to design a communicative
system a propaganda system for
nationalist forces for anti-muslim
forces for authoritarian forces you
could not build a better platform than
Facebook
we set out to investigate why Facebook
Twitter and Google are such powerful
tools from malicious actors who want to
spread this information in undermine
people's faith in democracy the first
stop was in Silicon Valley to meet with
the cofounders of blitz metrics Dennis
you and Logan young they teach social
media marketing and run advertising
campaigns on Facebook for the NBA champ
Golden State Warriors and more than a
hundred other clients Facebook is the
world's most powerful and sophisticated
targeting platform it is a database
instead of a social network Facebook
sorts its users characteristics into
hundreds of categories making it easy
for advertisers to target people with
great precision and you don't have to be
a statistics expert you can just click
on a few buttons and the system will do
the work for you in 2016 the Trump
campaign spent most of its hundred
million dollar digital advertising
budget on Facebook you and Yung
demonstrated how Facebook could have
been used to reach blue-collar workers
in Michigan a state that usually goes
Democratic but that Trump won by less
than eleven thousand votes I can be
based off income you know if I know the
average blue-collar worker makes fifty
two hundred K so I could say people that
are conservative or very conservative
they could be afl-cio members they could
be against you know immigration there's
all these other issues that we can
bucket in here we could even put in
labor union or the United Auto Workers
right if you have the kind of content
that's directly relevant to that
particular crew such as the US auto
industry isn't as strong as it used to
be so this is data that Facebook has
brought together from many different
sources not just their platform that's
right we have this information of your
membership we have your zip data we have
if you've made that donation we know the
kinds of products that you're buying in
a supermarket everything that you're
doing that doesn't involve cash usually
makes its way to Facebook
but the most powerful capability
Facebook provides comes from combining
its data with that of advertisers
themselves so think about the Trump
campaign they have all of the
information of the people that are
making donations they upload that to
Facebook then Facebook can say I'm going
to find friends of people that have
and then I could combine that with the
other day that we're showing and say how
many of those people are also in
Michigan and are also over 35 and are
also working in Detroit and are late you
know laid off at the Ford plant and you
can also text the messages that work
most effectively with that group yes
then you can spend just pennies to be
able to see how they're working and they
showed how a small amount of money spent
promoting a client's video resulted in
millions of views and I can see here we
spent five hundred six dollars and for
that we got a reach of ninety four
thousand ninety four thousand times I
showed up on someone's feet but it has
over twenty nine million views and the
reason is these shares this has been
shared four hundred twenty two thousand
times so really what you want to do when
you buy ads is generate shares that's
exactly it
the Russians were really good at pushing
incendiary content that people will just
have to engage and have to share the
Russians divisive content may have
reached one hundred and twenty six
million Americans on Facebook according
to the company but you points out the
ads were seen over and over again by the
same people appearing on news feeds
hundreds of millions of times and do you
think that these hundreds of millions of
impressions that they got had a real
impact maybe maybe not was it in
Michigan or Florida or place was it
close I don't really know but what I do
know is that they're saying how
effective Facebook is and how we can
micro target and how it's great for
advertisers that are selling furniture
and cars yeah at the same time you don't
think the hundred million impressions on
Facebook can't create an impact on an
election like you you can't have that
both ways right so of course Facebook
can influence election in fact we used
to joke about how you'd throw an
election using various tools that
Facebook which Facebook actually could
do Antonio Garcia Martinez worked at
Facebook from 2011 to 2013 and played a
central role in developing Facebook's
micro targeting system my responsibility
there was product manager for ads
targeting which meant basically turning
all your user data into money for
Facebook what role do you think Facebook
played in Donald Trump's election Oh
huge I mean if a little bit pundits get
things wrong all the time right but a
well-trained machine learning algorithm
trained on good data doesn't often come
up with the wrong answer right and I
spent years building tools to basically
human reason or human or you know
dominate human taste it's it's very
weird but don't you think that can be a
real problem when used to sell political
candidates and their messages rather
than consumer products right no I think
politics are somewhat different right at
the end of the day our democracy and our
political system depends on it and
that's frankly more important than
selling you a pair of shoes like no
question right but Martinez is much more
concerned about the way Facebook
encourages people to live inside their
own echo chamber what's also called a
filter bubble to me the bigger issue
that I really don't see a solution for
is the sort of filter bubble /pha can
use problem right where you know
citizens used to have a right to an
opinion and now they have a right to
their own reality you know Facebook
flatters their vision of the world and
they're never forced to challenge their
assumptions you know they can go off in
some rabbit hole of untruth Facebook's
mission is to give people what they want
on their newsfeed an executive providing
orientation drove that message home to
Martinez and his first day of work he
had this very sweeping vision of you
know the New York Times of you in fact
the accident formable question he's like
oh what is Facebook you know and some
dumb intern said oh it's a social
memories like no wrong write it is your
personalized newspaper they basically
feed you anything that you engage with
by engage means likes comments share
etcetera it like their news feed
algorithm is optimized to that Facebook
recently announced changes to its news
feed that will prioritize posts from
friends and news from sites that users
rate as trustworthy but the changes
could reinforce filter bubbles and do
little to stem the spread of bogus news
why is it so easy to disseminate fake
news on Facebook again I think it all
comes down to you know what
psychologists call cognitive dissonance
right the use of the world that flatter
your worldview you just eat up like
candy or french fries and just can't get
enough of it and that's that's why fake
news is so effective because it for the
world as you'd like to see it rather
than it actually is
today more than two-thirds of Americans
get news on social media do you think
Facebook has contributed to the
polarization America today yeah but I
don't think anyone had any notion that
it would reach the levels words reached
today which you have democracies that
basically can't function you can have
democracy in which you and I
can agree on a ground truth of values
and realities if you don't have that
then how do we form consensus around the
policy goal how do we solve any of
society's problems right information
bubbles exist but the breadth of
information that an average person today
holds is the largest in history Miko
Kaczynski is a psychologist at Stanford
who did path-breaking research on what
you can tell about people from Facebook
Likes we just look at likes that people
have not we actually the algorithm can
take likes from your profile your
Facebook profile and will be able to
very accurately reveal your
psychological traits your political
views your sexual orientation your
ethnicity whether you take drugs or not
and number of other sensitive and
intimate things kasinski thinks the
upside of using these new psychographic
profiling techniques in politics far
away's the downside making it possible
for politicians to adjust their message
in such a way as to make it relevant to
people it's great because it increases
an engagement of people in politics it's
great for the democracy but people can
be engaged because of very narrow issues
and engagement within a narrow political
point of view is not necessarily good
for democracy is it social networks are
a great advantage a great boon to the
democracy anyone can become a blogger
anyone can become a publisher well on
one hand it brings us all of those
people that say it's not real things but
on the other hand it protects us from
governments or powerful individuals or
corporations dominating the
communication channels but the
algorithms are channeling to you the
things you really want to see
so in some sense that undermines any
sense of truth or a common reality in
which people can talk and try to work
out policy together no there is data
that exists that shows that humans
always this is just human nature
we always occupied our own echo chambers
we always occupy the universe of me now
today
thanks to reputa recommendation systems
those universities of us of me and you
are the largest universes we ever had
and they're also overlapping to a great
extent I think the effect of the filter
bubble has yet to be quantified and I'm
willing to render a hypothesis that when
we get a decent full assessment of the
effect of filter bubbles it will be
different among different groups and
different people how have social media
platforms affected political discourse
social media platforms have divided us
have made a shallower you know the very
addictive nature of it interferes with
our ability to dive deeper into long
texts it interferes with our ability to
speak face to face at any depth a and
perhaps to come to some sort of mutual
awareness of agreement you know it does
structure our habits of thoughts and
ways that are not healthy for living
life in a complex world and living in a
democracy do you think that the spread
of junk news and disinformation on
social media platforms has undermined
truth in a sense if you're reading and
learning about the world through
Facebook what you're getting is a
mixture of traditional quality
journalism and completely out there
completely made-up stories that look
like journalism you're gonna have a
really hard time distinguishing what is
true and what is not and if you are of
the mind that you would like to
undermine our ability to think about
facts and coherently argue about policy
you're going to turn to social media to
get your word out there to mess with
people to frustrate people to confuse
people because nothing better has ever
been
invented Larry Kim in online marketing
consultant showed us just how easy it is
to spread this information on Facebook
he was troubled by all the fake news
sites that popped up during the 2016
presidential election last October he
ran a test to see if Facebook can
address the problem he took us through
the steps of his experiment
wanted to know if Facebook had closed
the loopholes and the whole effort took
less than an hour so first thing that I
did was we're gonna fake news website
basically to disseminate fake stories so
my blog decided to go with the name of
citizens and news networks the story
that I used was actually a very famous
fakest story about a donald trump
protester who is saying that he was paid
$3,500 to protest a trump rally that was
from the election yeah you can see Bob
that this is a really ridiculous looking
site it doesn't seem very authority of
it in any way I did this intentionally
because I wanted to see all the Facebook
kind of fake news police you know be
able to kind of catch this this little
this little hack in the act then what
did you do well so the next thing you
need to do is set up a Facebook page for
my fake website and that's really easy
to do and it takes you know one or two
minutes so if you want to promote a fake
news site on Facebook they don't check
it all when you sign up
no absolutely absolutely they don't
check I was claiming to be a media
outlet but you know that was all self
declared information and then I just
simply shared the fake news article to
my fake news Facebook page and now we're
almost in business here so you know step
three we need to just need to promote
this story to to an audience you know
using Facebook ads to boost exposure of
his fake article on Facebook news feeds
Kim spent fifty three dollars on a so
called engagement ad for his experiment
he targeted people in three swing states
key to Trump's victory Michigan
Pennsylvania and Wisconsin I went with a
demographic that is very very likely to
to eat this stuff up so for example
people who are Republicans who were
members of
the National Rifle Association people
who donated to conservative causes after
he selected the groups he wanted to
target he clicked on the boost post
button you know I just want to get
caught I want somebody at Facebook to
shut this down and say like you know
this is the violation of some term about
a keep in mind Facebook is a advertising
business and the ad was approved within
minutes so what happened did you
immediately start getting people posting
to it or reacting to it the reaction was
bonkers like people were clicking on it
and commenting on it and sharing on it
and liking it like crazy within an hour
about 5,000 people saw it for 450 bucks
that doesn't happen that often you know
I have companies that are spending
orders of magnitude more than 50 bucks
and they can't drive this type of
engagement what did you take away from
doing this experiment my takeaway is
this is appalling that fake news friends
undermine our systems of government so
it's very concerning that you know
people can still do this a year or later
after the after the election what do you
think can be done to address this
problem pretty obvious for stuff is
there should be some kind of an
application process you know like just
like when you sign up for a credit card
that you you know it's a kind of a
validation of advertisers to verify who
they are and if they are real or not
Facebook declined our request for an
interview it pains us as a company and
that our platform was abused in this way
Facebook Google and Twitter at each
announced a variety of measures to deal
with disinformation
these include tweaks to algorithms
political ad disclosure increased
security staffing and review of articles
by outside fact checkers Facebook's
approach to fact-checking is actually
not doing well people think that content
throughout the site is being checked
because they're seeing some disputed
tags and that's just not true Robin
Kaplan is a scholar at the data and
society Research Institute she focuses
on policy to deal with disinformation
and propaganda on social media platforms
do you think Facebook Twitter and Google
can address the problems of
disinformation over their platforms
without fundamentally changing the
economic model no I don't these are
private companies and that creates you
challenges because firstly they are
driven by their own goals and incentives
that need to align with their business
model
things like clicks likes and shares are
the metrics that are used to prioritize
or D prioritize content because that's
how ad revenue is based but those
signals don't actually tell us much
about whether or not that content is
truthful or important or valuable do you
think the companies can really solve a
lot of the problems by tweaking their
algorithms
I don't think algorithms are actually
going to fix this problem these
companies need to start hiring on
editorial staff and journalists people
who have been located within the
traditions of news media to start
informing some of the decisions that
platform companies are making in
reviewing content what do you think of
the company's argument that if they take
a greater role in curating content it's
going to lead to censorship we can
develop processes to make sure that they
are not censoring content arbitrarily so
I think we need to start having a
conversation about whether or not they
should be held to a higher standard of
norms and values that we've had with
print or radio or cable I think it's
time for platforms to step up to the
plate and accept the responsibility that
their media companies so they're not
neutral technology companies here's the
ironic thing right people say that
Facebook has too much power so as a
reaction they want Facebook to assume
more power by actually potentially
censoring or editing content on their
platform as a former employee I'm not
sure that I want Facebook becoming the
editor-in-chief to the world's
newspapers I'm actually not a big fan of
that solution do you think social media
platforms can deal with the problem of
echo chambers and fake news without
undermining their economic model in a
way there's nothing they can do about it
and B the companies they are is that
right I think that's right that's right
but one thing that might change is I
think people might get just more savvy
right they might understand that they're
looking
thank you I mean in some sense look
every every new technology is
characterized by in the initial period
of discovery being used by either
criminals or rogues or you know for
various negative for negative outcomes
and so where I think we're going through
social medias growing pains right now
it's too early to tell but I don't think
that that that society adjusts to these
movements like in Germany in the 1930s
radio and film became powerful
instruments of propaganda they were the
chosen instruments of Gibble's and of
Hitler and they worked beautifully for
them after World War two we confronted
the fact that propaganda was dangerous
we had a fervent public conversation
about it we had Commission's devoted to
it in order to deliver solid dependable
information and so no we have an
adjustment in the technology we've just
gotten lucky we have managed to manage
it
through the use of competition the
celebration of multiple voices and
through a practice of consensus but I
fear that that consensus is breaking
down
when a consensus breaks down power of
propaganda gets that much stronger in
the next concluding episode of this
special report how Russia and the
extreme right use automated social media
accounts known as BOTS to spread
disinformation and propaganda
you
