millions of Facebook profiles allegedly
used for political purposes information
that could have helped Donald Trump and
influence the brexit vote can data swing
elections and his privacy really
possible in this age of social media
this is inside story
hello there and welcome to the program
I'm Laura Kyle social media giant
Facebook is under fire amid allegations
that the data of millions of its users
was misused for political ends
a British political consultancy firm
Cambridge analytic harvested the
information through an online
personality test
this was allegedly used to help both the
Trump presidential campaign in the US
and groups in favor of BRICS at
Britain's exit from the European Union
Facebook CEO Mark Zuckerberg denies any
wrongdoing saying the creator of the
personality test app acted illegally but
that hasn't satisfied the US Congress
the UK Parliament nor the European
Parliament they've all summoned
Zuckerberg to answer questions on user
privacy meanwhile Cambridge analytic has
suspended its boss
Alexander Nicks a whistleblower from
within the company revealed what was
being done with the data Cambridge
analytic was birthed out of a company
called SEL group which is a military
contractor based in London it this data
was used to create profiling algorithms
that would allow us to explore mental
vulnerabilities of people and then map
out ways to inject information into
different in different streams or
channels of content online so that
people started to see things all over
the place that may or may not have been
true this is a company that that really
took fake news to to the next level by
pairing it with algorithms so how did
all this happen well in 2014 270,000
users downloaded an app this is your
digital life and took an online survey
this meant their Facebook information
could be accessed but it also gave the
app access to their friends data a total
of more than 50 million profiles were
accessed and the information sold on to
Cambridge analysts occur for political
purposes
now Facebook says this violated company
policy and it received assurances in
2015 that the data was destroyed but
there are now reports it wasn't instead
it was used to create psychological
profiles of voters these were allegedly
used to help the Trump presidential
campaign Trump's campaign manager Steve
Bannon was on the board of Cambridge
analytical okay let's bring in our
guests now in the Pittsburg via Skype
Larry McGann CEO of connect safely org
in London Jason moon an ethical hacker
and Internet security specialist and in
Rome we hustle back count co-founder of
data ethics on EU that's an independent
think-tank promoting data ethical
products and services thank you very
much all of you for joining us today
Larry start with you got two rather
unsettling aspects to this story haven't
we one that personal data was harvested
the other that it was used to manipulate
voters but who's the real bad guy here
is it Facebook or is it Cambridge
analytic huh well or or is it the
professor who gathered this information
presumably for academic research and
then provided it to Cambridge analytic a
Facebook is blaming him saying that he
violated their agreement although he is
actually pushing back I was reading just
an interview with him a few minutes ago
I think with a BBC where he said that in
fact that what he was doing was
perfectly normal and and par for the
course but I think there's a lot of
culpable organisations and individuals
and this obviously Cambridge analytical
although this is the business they're in
they brag about this I suppose that's
you know what what they do the Facebook
needed to be more careful they have
since said they have are doing a better
job vetting these apps and claimed that
this wouldn't happen again but also I
think that the fact that it's not only
the 270,000 people but if he pointed out
it's their friends it's the fact that
when somebody gives information to an
app or a game or something on Facebook
they're not only giving their own
information I think that's fair game if
they know what they're doing but they're
giving information about their friend
and I question is that really the way
you treat your friends to disclose their
information unwittingly just because you
want to play a game or even app but they
didn't know about that that was the
point wasn't it Facebook didn't make
that clear right Facebook I think that
if you read the permissions carefully
you will notice that you are turning
over some public information about your
friends now it's information your
friendship
but nevertheless you're turning that
over and that's usually in the
disclosure there was the type of
disclosure here but again you know
people click on ads apps all the time
they don't read all the fine print and
certainly they had no way to know that
the information would get from this
researcher over to Cambridge analytical
and eventually into the Trump campaign
that nobody knew including Facebook
absolutely
okay well Jason let's look at this
professor I mean was it perfectly normal
behavior to give Cambridge analytic here
all of this information well I mean what
we have to remember is this is how
Facebook makes its money this is a big
part of how Facebook makes its money
I think it's morally repugnant what
happened but I don't know whether you
can really blame the professor as such
because um it's kind of like you know
Einstein taught us how to split the atom
but then other people made nuclear bombs
with that you know Facebook provided the
sort of facility for this abuse to take
place I think the Pandora's Box was
first opened by actually in 2013 by I
mean this whole thing gets Calder
psychometrics psychometrics has kind of
been the power of it has been really
known since about 2013 where there was a
sort of an online experiment done with
it and I think that obviously tweaked
the interest of you know what then
became Cambridge an analytic so I mean
that they have a peak that they bear
some of the responsibility but um it's
not like this wasn't known about of
course they've exploited this
information to the nth degree and it
shows you the sheer power of it so
hopefully now there'll be some you know
some some clamping down on privacy
rights and stuff for just normal people
on social networking platforms but I
don't think any one individual bears the
full brunt of the responsibility here
the blame does go sort of between all
parties concerned they've all been very
very slack and not really forthcoming
and honest about how bad this has been
either constantly sort of wiggling out
of not being truthful about the numbers
that have been involved or anything even
now trying to deny that they to bear any
responsibility greed you broadly agree
with with what's been said so far this
whole business is rather unsavory but
not necessarily illegal
and I mean I'm not sure if I agree
completely I mean one thing is with
Facebook I mean what they created is a
whole business model model around
harvesting data personal data on people
they have a design structure of their
platform that is based on tracking
people and then so on and so forth and
and in general if you if you're looking
at for example from where I'm sitting
from a European perspective and now with
a new EU regulation there will be much
tougher legal provisions and
requirements in regards to the design of
your platform the way in which you
retrieve consent from from people you
can do the same kind of invisible
collection and sharing of data that is
in some way I would say it's embedded in
the design of Facebook so in many ways I
see a lot of responsibility and and lack
of accountability of Facebook in this
case so you say that Facebook was built
around the gathering of this kind of
information the very nature of it makes
us give Facebook this information but
did it ever intend for this information
to be used in the way that it has to
influence elections I mean no of course
not there's a policies against this but
I'm talking about the design if you
create a platform and a technology that
where the design is is made to attract
users and to to actually use days for
different ways then I mean with every
technology it is it can both use be used
and it can be abused and and what I see
now when I'm following is I see a
movement of technology businesses and in
companies that are creating different
kind of technologies where you can't
track users and and that are based of
different kind of business models that
are not necessarily made to track or to
follow users around and collect data on
mess and I think that's the the
direction we need to move in there's
been a particular development in the way
in which technologies have been
developed and business has been
developed online
and and this needs to change and and
what what supports that change is of
course the new EU regulation the
different provisions things like data
protection by design which is a design
requirement or provisions on consent
informed consent differently different
requirements in regards to data
profiling so these things have to change
Larry the the EU the UK Washington
they're all calling for Zuckerberg to
come and present his case he said he's
going to be speaking within the next 24
hours of the time that we're now
recording this program
you've met Mark Zuckerberg what's he
likely to say I think he'd like me to be
somewhat apologetic I would hope I would
hope he would be very transparent
I would hope he would be open for not
just suggestion but the possibility of
some type of government if not
regulations at least some type of
oversight because I think that we are
talking about things that are affecting
the public sphere here just if for
example television and radio in the
United States you can't to take it and
add a political ad out on television or
radio or even in print without
disclosing where the money is coming
from so I hope he would be open to a
greater amount of transparency but I do
think he has to come forward I think it
has to be him and/or Sheryl Sandberg the
two top leaders and by the way an answer
to your last question I think initially
these technologies on Facebook were
designed for commercial purposes to sell
products but they figured out before the
2016 campaign that there was a market
the political advertising and in fact
they put out documents talking about how
they could segment their audience that
out you could reach people from very
liberal to very conservative and
everywhere in between and they could
deliver you a specific audience based on
at least certain gradiation zuv
political ideology I don't think they
ever intended this level of
psychographic research getting into the
hands of a campaign but they certainly
eventually decided they were in the
business of selling political
advertising and giving people a lot more
granularity than you could get on
television or in print
yeah Jason is truest at this information
it's immensely powerful and therefore
presumably immensely valuable do you
think it has actually managed to sway
elections I do I think I think it's
definitely a quite a powerful quite a
potent contributing factor I mean it's
it's kind of daft in a way because it's
sort of obvious that it could be used
for this in that like like the other
guests said it was it was used to
deliver you adverts and you know
psychometrically profile you to decide
you know what to influence you to buy
something so it's not that much of a
step from that to influence influence
you to vote in a certain way perhaps or
perhaps to abstain from voting this is
the important thing where there's a lot
of sort of evidence to suggest that it
wasn't so much about making you vote
because people I think people think
there's no way you know I'm a liberal
there's no way you could get me to vote
for Trump yes but perhaps you could be
influenced to abstain from voting in
your specific state and that could be a
very very powerful tool to manipulate
the outcome of an election you know
things like that and I think the public
have lost all of all the ability to
check to be able to sort of gauge what's
real news what's fake
news and all the rest of it I mean like
you were saying some of the examples
about you know broadcast media and
things like that I mean how is it you
know I don't see Facebook really doing
much they said they would but they
haven't done much to sort of thwart this
immense problem with all the fake
profiles and stuff which make all their
you know the troll BOTS and all the rest
of it I mean it's so difficult to tell
if you're even arguing with a real human
being if a Facebook page is posting news
links and it's natural real human being
that's posted them are the news things
even real news you know it's it's a it's
a nightmare for your average sort of
Facebook user to distinguish between you
know what's what's fact and what's
fiction so there's a lot of work that
Facebook could be doing to help resolve
this problem like I think Greek we give
us some examples of exactly what
Facebook could do to make users trust
the content that they see more well well
I as I said it's a question of design of
the service so so I'm not sure if
Facebook
actually do that but I think that you
can design technologies that that in a
way from per default respect users
rights and and and keep your data safe
and and have technical safeguards I mean
in in general if you have an API that
that shares not only the the profiles
that you access to but also the friends
that is a specific design of a
technology that that that allows this
kind of sharing of data I think you need
both in terms of technical design
different kind of technical design of
services but you also need a different
kind of accountable process where as a
company and then of course we need to we
need a law that is implemented that is
actually you have a system around where
where users can get there it can can get
them get help and where you where you're
supporting this development Larry do you
think we can ever stay ahead of the
curve here I mean now of course Facebook
has said that it shut down this ability
to share users friends profile but of
course that was done after the event
after 50 million users information had
gone out we ever going to be able to
proactively work in this situation well
ahead of the curve is perhaps a little
bit more optimistic that I would be but
if you can sort of keep up with the
curve or you slightly behind the curve
that would still be great progress I
think there are things they could do for
example and when we talk about the box
there are ways to know that a human
being is at the keyboard versus a
machine so there are ways you can
virtually eliminate box there are ways
you can require more transparency and
force more transparency artificial
intelligence
I know it's over often hyped and maybe
won't deliver all that it promises to do
but certainly there can be some
algorithms that can begin to catch some
of these things and also a lot more
you've been moderators for throughout
the world not just located in countries
the scattered throughout the world but
for example when you're talking about
the u.s. election yuuma neurotic
moderators based in the US you
understand US culture can probably go a
long way towards helping at least to
moderate some of these more crazy
exchanges that are going on whether
they're between
the Newman the troll farm staffed by
people but but not actually organic
discussions and these aren't helping
things and of course the other is
transparency in advertising know where
the money is coming from and who the
actual advertiser is a Jason how much of
the responsibility should come down to
us as the users I mean it could be
argued that the information was there in
the fine print it was said that your
information was freely available I
believe it was also said that your
friends information was freely available
no one reads those terms and conditions
they're so small they're in a completely
different area and they take forever but
should we now be paying more attention I
think well one lesson to be learned from
this is don't do any more of those IQ or
personality test things that you see
constantly say suppose for sure
but I do think that it should be illegal
that I can share the information of all
my friends to a third party so there
there should be a line drawn there and
and if this highlights anything it
highlights that that is sorely lacking
and they need to legislate that because
I don't think you can so much blame the
user because like you say you can't read
all the reams and reams of small print
you wouldn't really even understand the
ramifications of that anyway and even if
you did understand that and you just
decided oh I don't mind sharing all my
friends data well your friends might
mind so I think that that should be
illegal you should be allowed to share
your data and it's your own fault if you
don't read the fine print but you
shouldn't be able to you know share that
the information about of all your
friends
that's wrong okay I mean this
information Jason we covered that it's
been used for advertising it's been used
for voting what else could it be useful
do you think well this this is this is
the scary thing I mean now now the full
sort of power of it has really been
highlighted I mean what where could it
work it it where could it lead I mean
it's it I think it's done quite a lot of
damage to the sort of fabric of the
culture in a way I mean we've seen
incredible polarization through through
this process which has only been
exacerbated and sort of fuelled by this
this this process this technique as
massive polarization across sort of
racial ethical political social divides
all the rest of it and then obviously
culminating in the extreme example of
you know putting what you could say and
outright present it president in the
White House so it's it's it's certainly
dangerous stuff and they need to look at
it very very very carefully because it
goes it goes a lot deeper than just you
know just arguing with some sort of
troll on on a Facebook News comments
section or whatever I mean it's I think
it can't potentially be quite quite
harmful and you know and it's an
infringement on your own personal
privacy so it's I think it's it's more
serious than the reaction that Facebook
is so far given right doesn't seem to be
in sync with exactly how serious this is
in my opinion Larry do you think
Zuckerberg has taken that on board yeah
I would agree with that I mean the
consequences are enormous I mean Donald
Trump likes to claim that all of the
Russian interference if it happened he
hasn't fully acknowledged if it have
happened didn't have any impact in the
election and you know the fact that when
you think about how candidates
legitimately spend money they buy long
signs they buy television advertising
they they go out and give speeches all
of these things are designed to sway
votes and if those work at least a
little bit it's hard to imagine that the
massive amount of online data
manipulation and and in propaganda
haven't had some impact especially when
you consider how narrowly Trump won in a
few key states he lost it he lost the
general election by three million votes
and he won some states by he with forty
thousand I think that this stuff is
enormous ly powerful and by the way
getting back to that very good
suggestion about keeping people from
sharing other their friends information
facebook says that when you share your
friends information you're only sharing
what they share publicly and a lot of us
on Facebook tend to share far more
publicly than we may realize and if I
may put in a little plug my own website
Larry's worldcom I have several articles
on the front page about controlling your
privacy on Facebook I don't think you
should have to read by blog to know how
to do this it should be a lot
but the fact is that if you take the
time you can limit what's of publicly
available on your profile and that could
have kept you out of this database or at
least some of your information out of
this database but again I would like to
see that a lot easier and perhaps the
default rather than something that you
have to engineer yeah I mean greedy
that's let's put upon the problem isn't
it do you take the time to go and adjust
your privacy settings and everything on
Facebook the way it's set up is so quick
and easy to use you mentioned before
that there are other technology
companies that are developing
alternatives but really is anyone going
to take the time to find out about them
to switch over I mean Facebook is so
pervasive isn't it we're kind of stuck
with it yeah I mean I don't think it's
up to the users to figure out this
there's lots of alternatives I think
it's gonna come all by itself we're kind
of in a data ethical wave you could call
it almost like the environmental
movement and you see it all over the the
law the new EU law is is in a sense a
symptom of this change of awareness
around what does the role of data data
is power information as power these
different kinds of technologies in like
for example if you look at the legality
of what has been going on now then there
I mean from the 25th of May when the EU
data protection regulation is truly
implemented or goes into place and
there's several things in in this case
that wouldn't be legal at all in there
for example in the way in which you you
get consent from users Facebook has got
consent from users to use their data and
the way that in general the thing of
sharing you your your friends data is is
it's not it is illegal so so there's a
several things that that that movement
it's a whole cultural movement or
societal movement that I think it's kind
of it's it's gonna change itself just
like the environmental movement right
now today if you a company that doesn't
it that you're not environmentally aware
if you don't use if you don't treat the
environment well you loosen your brand
you lose customers you lose your
investors and I think it's I hopefully I
am optimistic in that way that that both
technology and law
and users themselves with wit will make
this happen
okay I just the is it too late though I
mean our data is already out there isn't
it and there's no reassurances from
Cambridge analytical that they've
deleted what they gathered and one
wonders how many other companies have it
I wouldn't believe for a second that
they've deleted it I mean they were
photographs taken the other day outside
their offices where they were what
looked like it trying to dispose of huge
amounts of documentation
I mean what's in those documents that
they were getting rid of and moving from
the offices before the investigators
raid them or whatever
yeah I mean the Pandora's box has been
opened the damage has already been done
so of course it's great if things get
better but I mean it's already
influenced you know to perhaps more
elections that's pretty bad collateral
damage if you ask me I mean I would love
to see a system whereby even a simple
sort of red amber green or something so
people at least had informed consent
like maybe around every news item that
you see on your newsfeed the source is
graded and there's a box around it which
is either red amber or green sort of
denoting you know like the guy was
saying gradients of you know how
reliable that information might be the
source of that information
I don't know simple things like that
would be relatively easy to implement I
and why do you have to fight with the
settings why are the settings
automatically at share everything and
then you have to be a kind of tech
expert to fight with it and figure out
how to you know what I mean it's exactly
there's not much cooperation coming from
you know Facebook absolutely and until
we get that cooperation I'm going to go
to Larry's page and check out how to
increase my privacy settings thanks very
much sir for that Larry thanks also to
Jason moon and gree Hasselbeck great
discussion thanks for joining us on
Inside Story and thank you too for
watching you can see the program again
anytime by visiting our website this
aljazeera.com and for further discussion
do go to our Facebook page that's
facebook.com slash AJ inside story you
can also join the conversation on
twitter our handle is at AJ inside story
from me Laura Kyle and the whole team
here it's bye for now
you
you
