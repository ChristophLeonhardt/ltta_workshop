at artificial intelligence continues to
integrate into our everyday lives a
growing chorus of criticism is
highlighting the dangers of handing
control to machines for example there's
now a supercomputer that's able to
create an artificially intelligent child
you can recognize objects such as cars
and people in real-time were
outperforming any human made algorithms
another system made by Google has
created a machine that took just four
hours to learn the rules of chess and
then beat her world leading program
meanwhile tech giant Facebook says its
program can detect suicidal behavior by
analyzing user information and Facebook
CEO Mark Zuckerberg believes this is
just the beginning in the future
AI will be able to understand more of
the subtle nuances of language and will
be able to identify different issues
beyond suicide as well my colleague
Colin Bray discussing artificial
intelligence with a panel of experts
well I can understand the fear part of
what we need to understand with
artificial intelligence is that we're
just at the beginning this is just the
tip of the iceberg
what's gonna happen in the near future
is that you're gonna have predictive
analytics which will allow AI to predict
your desires before you even know what
you want just the thought of machines
telling me what I want it already makes
me uncomfortable and but we see that
happening you know in our lives
instantly getting recommendations from
these systems and they're constantly
intervening in ways that we don't expect
that we didn't ask for the future is
technological so we need to start
understanding it everyone it shouldn't
be left to a couple of people in
industry or in government to dictate how
this goes we all have to be a part of
this process of moving forward in the
future with AI I think that we need to
be careful about the idea that the
future is technology and we have to
adapt to it people are talking about
implanting technology in the body
in question you know and saying the
technology itself is human or is a
successor to humanity even this is this
is very dangerous
the bishop this is where the line has to
get drawn doesn't it really because on
the one hand we all demand our devices
know what we're doing where we're going
make these decisions for us we carry
them around in our pockets all the time
and then we're the first ones to moan
when tech companies have information on
us and seem to be able to predict our
behavior we then find that creepy yeah
that happens and it potentially has
political impacts as well that the there
are people suggesting that for example
the the American last American election
and the British brexit vote was in part
informed by complex analytics
manipulating the images that people saw
and related to for the very first time
on this planet we're all going to have
an enormous amount of power not just a
few people every single one of us is
going to have an enormous amount of
power through the power of AI and we
have to decide as individuals and
societies how we want to process that
ability that that amount of power I'm
not too comfortable with the idea that
we are going to be powerful I don't know
the technology is out to enslave us but
I do think that technology is upsetting
the social balances and the economic
balances and ecological balances that
have evolved over millions and hundreds
and dozens of years and this is the
great danger you can blame the
technology but it's not the technology
it's us and so I disagree with the fact
that we are as we are separate from the
technology it is a continuum separate
technology and humanity is I think the
most dangerous thing to do because when
self-aware machines finally arrive is
that going to be the new enemy if we
continue this narrative so the new
narrative has to be technology is a part
of us it's a reflection of who we are
that is the narrative we should be
thinking about
