this morning EU officials approved a
plan that would force social media
companies to take responsibility for
offensive and violent content on their
platform Facebook already employs 4,500
content moderators around the world and
our partners at the Guardian obtained
more than a hundred leaked training
manuals which for the first time show
exactly what's allowed on the world's
largest social network and what isn't
moderators work on a special page called
the single review tool there's a menu of
options to review millions of reports
flagged by Facebook users then
moderators say they sometimes have as
little as 10 seconds to decide whether
to ignore escalate to a manager or
delete each post so how hard a job is it
let's start with the Holocaust Facebook
is committed to free speech and in the
u.s. that covers Holocaust deniers
but Holocaust denial is illegal in 14
countries although the manual says
Facebook is only concerned with four
countries that actively pursue the issue
with the company so moderators have to
decide if a post questions the existence
of the Holocaust or minimizes the number
of victims
if so policing violence is far more
complicated in one of the leaked
documents Facebook acknowledges that
people use violent language to express
frustration online so for instance
that's allowed but threaten the
president that's not okay because heads
of state are in a protected category
animal abuse
uh that's allowed child abuse amazingly
images of non-sexual child abuse are
allowed to unless the child abuse quote
is shared with sadism and celebration
judging the difference between an abuse
child and a sadistically abused child
back up to the moderators and their
managers
Facebook allow some videos of violent
deaths such as the Facebook live police
shooting of falando Castile last year
but asks moderators to mark them
disturbing to protect minors it also
allows live-streaming of suicide
attempts and asks moderators to escalate
each one videos are to be deleted once
the person has been rescued or dies when
a proposed suicide method is deemed
unlikely to succeed and any suicide
threat more than five days in the future
if moderating violence is hard
moderating sex seems impossible
a 65 slide Facebook document titled
sexual activity explains that these
posts are okay but add any detail about
how when or where all handmade art
showing nudity and sexual activities
allowed but digitally made art about
sexual activity is not even if a lot of
handmade art is more pornographic than
the real thing
Facebook admits in the leaked documents
that the line between the two is
difficult to enforce but it asks the
moderators to do so anyway Facebook
processes 1.3 million posts per minute
and the documents show that the company
is at least trying to come up with
policies on everything from profanity to
cannibalism it has automated systems to
root out some extreme content and the
company has promised to hires 3,000 more
moderators it should hurry
sources say current moderators move on
quickly and suffer from anxiety and PTSD
and it's no wonder why
Oh
